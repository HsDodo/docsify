### 牛客面经

> #### **问题 1**. 怎么保证消息发送给用户的时候不丢失，消息顺序如何保障?

使用 Apache Kafka 实现消息的可靠发送和顺序保证是非常常见的做法。Kafka 是一个高性能的发布/订阅消息系统，非常适合处理大量的实时数据流。下面是如何使用 Kafka 来确保消息的可靠性和顺序性的步骤和示例代码。

###### 1. Kafka 的基本概念

- **Topic**: 主题是 Kafka 中消息发布的逻辑分类。
- **Partition**: 为了提高吞吐量和容错能力，每个 Topic 可以分为多个分区。
- **Replication**: Kafka 允许对分区进行复制以提高数据的可用性和可靠性。
- **Consumer Group**: 一组消费者可以组成一个 Consumer Group 来消费同一个 Topic 的消息。

###### 2. Kafka 保证消息可靠性的方法

- **持久化**: Kafka 将消息写入磁盘，保证消息不会因为内存溢出而丢失。
- **副本**: Kafka 会对消息进行复制，即使某个节点失败，消息仍然可以从其他节点读取。
- **ACKs**: 生产者可以配置等待确认的级别，比如 `acks=all` 表示只有当所有副本都收到消息时才返回确认。

###### 3. Kafka 保证消息顺序性的方法

- **单分区**: 如果消息必须按照顺序处理，可以将所有的消息发送到同一个 Topic 的同一个分区。
- **客户端排序**: 客户端可以按顺序发送消息，并且确保消息的顺序性在客户端级别得到保证。

**示例：**

生产者示例

```go
package main

import (
	"context"
	"fmt"
	"log"
	"os"
	"sync"
	"time"

	"github.com/confluentinc/confluent-kafka-go/kafka"
)

func main() {
	// 创建一个 Kafka 生产者实例
	p, err := kafka.NewProducer(&kafka.ConfigMap{"bootstrap.servers": "localhost:9092"})
	if err != nil {
		log.Fatalf("Failed to create producer: %v", err)
	}

	// 创建一个同步通道来接收生产者的确认
	deliveryChan := make(chan kafka.Event, 10000)

	// 启动一个 goroutine 来监听 delivery channel
	go func() {
		for e := range deliveryChan {
			switch ev := e.(type) {
			case *kafka.Message:
				if ev.TopicPartition.Error != nil {
					fmt.Printf("Delivery failed: %v\n", ev.TopicPartition)
				} else {
					fmt.Printf("Delivered message to topic %s partition [%d] at offset %v\n", *ev.TopicPartition.Topic, ev.TopicPartition.Partition, ev.TopicPartition.Offset)
				}
			}
		}
	}()

	// 创建一个 Topic 的单分区
	topic := "ordered_topic"
	numPartitions := 1

	// 创建 Topic (如果不存在)
	if err := createTopic(topic, numPartitions); err != nil {
		log.Fatalf("Failed to create topic: %v", err)
	}

	// 向 Topic 发送有序消息
	var wg sync.WaitGroup
	for i := 0; i < 10; i++ {
		wg.Add(1)
		go func(i int) {
			defer wg.Done()
			message := fmt.Sprintf("Message %d", i)
			p.Produce(&kafka.Message{
				TopicPartition: kafka.TopicPartition{Topic: &topic, Partition: 0},
				Value:          []byte(message),
			}, deliveryChan)
		}(i)
	}
	wg.Wait()

	// 等待所有消息被确认
	time.Sleep(2 * time.Second)

	// 关闭生产者
	p.Close()
}

// createTopic 用于创建 Kafka Topic
func createTopic(topic string, numPartitions int) error {
	adminClient, err := kafka.NewAdminClient(&kafka.ConfigMap{"bootstrap.servers": "localhost:9092"})
	if err != nil {
		return fmt.Errorf("failed to create admin client: %v", err)
	}
	defer adminClient.Close()

	// 创建 Topic
	topics := []kafka.TopicSpecification{
		{Name: topic, NumPartitions: numPartitions},
	}

	results, err := adminClient.CreateTopics(context.Background(), topics)
	if err != nil {
		return fmt.Errorf("failed to create topic: %v", err)
	}

	// 等待结果
	for _, result := range results {
		if result.Error.Code() != kafka.ErrNoError {
			return fmt.Errorf("failed to create topic %s: %v", topic, result.Error)
		}
	}

	return nil
}
```

消费者示例

```go
package main

import (
	"context"
	"fmt"
	"log"
	"os"
	"time"

	"github.com/confluentinc/confluent-kafka-go/kafka"
)

func main() {
	// 创建一个 Kafka 消费者实例
	c, err := kafka.NewConsumer(&kafka.ConfigMap{
		"bootstrap.servers": "localhost:9092",
		"group.id":          "test-group",
		"auto.offset.reset": "earliest",
	})
	if err != nil {
		log.Fatalf("Failed to create consumer: %v", err)
	}

	// 订阅 Topic
	topic := "ordered_topic"
	err = c.SubscribeTopics([]string{topic}, nil)
	if err != nil {
		log.Fatalf("Failed to subscribe to topic: %v", err)
	}

	// 运行消费者
	ctx, cancel := context.WithCancel(context.Background())
	go func() {
		for {
			select {
			case ev := <-c.Events():
				e := ev.(*kafka.Message)
				fmt.Printf("Consumed message at topic %s partition %d offset %v with key %s and value %s\n", *e.TopicPartition.Topic, e.TopicPartition.Partition, e.TopicPartition.Offset, string(e.Key), string(e.Value))
			case err := <-c.Errors():
				fmt.Fprintf(os.Stderr, "Consumer error: %v\n", err)
			case <-ctx.Done():
				return
			}
		}
	}()

	// 等待一段时间
	time.Sleep(10 * time.Second)

	// 关闭消费者
	cancel()
	c.Close()
}
```

**注意事项**

- **单分区**: 确保所有消息都发送到同一个分区，以保持顺序。
- **确认机制**: 使用 `acks=all` 确保消息可靠地发送到所有副本。
- **错误处理**: 处理好错误情况，确保消息能够正确地发送和消费。
- **消费确认**: 在消费者端确认消息已经被正确处理，以便 Kafka 可以安全地丢弃已消费的消息。

> ####  **问题2.** kafka生产者的参数会设置哪一些？

Apache Kafka 生产者提供了多种配置选项来调整其行为，以满足不同的性能和可靠性需求。下面是一些常用的 Kafka 生产者配置参数及其说明：

1. 必要配置

- **`bootstrap.servers`**: Kafka 集群的地址列表，例如 `"localhost:9092"`。这是连接到 Kafka 集群所必需的配置。

2. **性能相关配置**

- **`acks`**

  : 设置生产者需要等待的确认级别。

  - `0`: 不等待任何确认，即发送完消息立即返回，性能最好但消息可能会丢失。
  - `1`: 等待 leader 写入消息的确认。
  - `-1` 或 `all`: 等待所有 in-sync replicas (ISR) 写入消息的确认。

- **`retries`**: 当发送消息失败时的最大重试次数。

- **`batch.size`**: 生产者发送消息前，消息在缓冲区中的最小大小。增加此值可以减少网络 I/O 的次数，从而提高性能。

- **`linger.ms`**: 批次发送消息之前等待的时间（毫秒）。如果在这段时间内有足够的消息填充批次，将提前发送。

- **`buffer.memory`**: 生产者可用的总内存字节数，用于缓存等待发送的消息。

3. **可靠性相关配置**

- **`compression.type`**: 消息压缩类型。可以选择 `"none"`, `"gzip"`, `"snappy"`, 或 `"lz4"`。压缩可以显著减少网络带宽使用，但会增加 CPU 负荷。
- **`max.in.flight.requests.per.connection`**: 每个连接允许的最大未确认请求数量。设置为 `1` 可以确保消息的顺序发送。
- **`max.request.size`**: 生产者发送的请求的最大字节大小。这有助于避免由于请求过大而导致的错误。

4. **其他配置**

- **`message.timeout.ms`**: 生产者等待消息确认的最长时间（毫秒）。如果在这个时间内没有收到确认，消息将被重试。
- **`delivery.timeout.ms`**: 生产者等待消息交付的最长时间（毫秒）。如果在这个时间内消息没有被交付，将抛出异常。
- **`client.id`**: 用于标识生产者客户端的字符串。
- **`key.serializer`**, **`value.serializer`**: 指定键和值的序列化器类，默认情况下使用 `org.apache.kafka.common.serialization.StringSerializer`。

> #### **问题3.** 何保障缓存数据库一致性？

##### 采用数据同步机制

1. **使用消息队列进行数据同步**

- **原理：**当数据库发生数据更新操作时，将更新消息发送到消息队列。缓存系统监听消息队列中的消息，并根据消息内容对缓存进行相应的更新操作。这种方式可以解耦数据库和缓存的更新过程，提高系统的可扩展性和容错性。

- **示例：**在一个大规模的电商促销活动中，当商品库存数据库发生频繁的库存更新操作时，每个库存更新事务会向消息队列发送一条消息。缓存系统中的多个工作者进程从消息队列中获取消息，并根据消息中的商品 ID 等信息更新缓存中的库存数量，确保缓存和数据库的库存数据一致。

2. **数据库事务与缓存操作的协同**

- **原理：** 在数据库事务中包含缓存操作，确保缓存和数据库的更新操作作为一个原子操作来执行。如果数据库更新成功但缓存更新失败，事务可以回滚，反之亦然。这样可以避免由于部分操作成功而导致的一致性问题。

- **示例：** 在一个在线订票系统中，当用户预订一张机票时，数据库事务中包含了更新机票库存表和更新缓存中的可用机票数量两个操作。如果在更新缓存时出现故障，数据库事务将回滚，机票库存表也不会被更新，从而保证了数据一致性。

##### 缓存清除机制

1. **基于时间的过期策略**

- **原理：** 为缓存数据设置一个固定的过期时间。一旦缓存数据超过这个时间，就会被视为无效，下一次查询时就会从数据库重新获取数据并更新缓存。这种方法简单易行，但可能会因为过期时间设置不合理而导致缓存命中率下降或者数据暂时不一致。

- **示例：** 在一个新闻网站中，新闻文章的缓存可以设置为 1 小时的过期时间。1 小时后，当用户再次访问该文章时，缓存中的旧数据将被清除，系统会从数据库中重新获取最新的文章内容并更新缓存。

2. **基于事件的缓存清除**

- **原理：** 当数据库中的数据发生特定的更新事件（如插入、修改、删除操作）时，系统会发送一个事件通知，触发相关缓存数据的清除。这样可以保证在数据库数据发生变化后，缓存中的旧数据不会继续被使用。

- **示例：** 在一个社交网络系统中，当用户删除了一条动态时，数据库中的相应记录被删除。同时，数据库会触发一个事件，通知缓存系统清除与该条动态相关的缓存数据，例如包含该动态的用户动态列表缓存、相关的推荐缓存等。

> #### **问题4.** 表中有十个字段，你会选择自增ID还是UUID作为主键？为什么？

在设计数据库表时，选择合适的主键类型非常重要。对于是否使用自增ID (`AUTO_INCREMENT` in MySQL) 或 UUID（Universally Unique Identifier）作为主键，我们可以考虑以下几个因素：

**自增ID**

- **优点**:
  - **简单且高效**: 自动生成，无需额外计算或查询。
  - **顺序性**: 生成的ID通常是递增的，这有助于某些查询操作的性能。
  - **占用空间少**: 通常使用整数类型，占用的空间较少。
- **缺点**:
  - **不支持分布式环境**: 在分布式系统中，多个服务可能需要同时生成ID，自增ID在这种情况下难以实现。
  - **可预测性**: 由于ID是连续的，可能会泄露一些内部信息，如插入记录的数量和时间间隔。

**UUID**

- **优点**:
  - **全局唯一性**: 每个UUID都是唯一的，适用于分布式环境。
  - **隐私保护**: 不像自增ID那样容易被猜测。
  - **灵活性**: 可以在没有数据库连接的情况下生成，并且可以在任何时间任何地点生成。
- **缺点**:
  - **占用空间大**: UUID一般为16字节（32位字符），比自增ID占用更多的存储空间。
  - **索引效率**: 对于某些数据库来说，使用UUID作为主键可能会导致较差的索引性能，尤其是在范围查询中。

**结论**

- 如果你的应用是**单体应用**或者不需要考虑分布式环境，**自增ID**是一个很好的选择，因为它简单、高效且占用空间小。
- 如果你的应用是**分布式系统**，或者你需要确保ID的唯一性跨多个服务器或服务实例，**UUID**是一个更好的选择，尽管它会占用更多空间。

**具体到你的场景**

如果你提到的表只包含十个字段，并且这个应用不是分布式的，那么使用**自增ID**可能是更合适的选择。它既简单又高效，并且在大多数情况下可以满足需求。

但是，如果考虑到将来可能扩展到分布式环境，或者有其他特定的安全性和唯一性的要求，那么使用**UUID**会更加稳健。在实际工作中，还需要考虑团队的技术栈偏好以及现有的基础设施等因素。

> #### **问题5.** 为什么自增ID更快一些？UUID不快吗？它在B+树中存储是有序的吗？

自增ID（通常称为序列或自动增长ID）和UUID（通用唯一识别码）在数据库中的使用场景和性能特点有所不同。下面详细解释一下这两种标识符的特点以及它们在数据库中的表现。

**自增ID的特点**

- **生成简单**：自增ID通常由数据库系统自动管理，每次插入新记录时自动递增。
- **有序性**：自增ID是连续递增的，这使得它们在B+树索引中天然有序，有助于提高某些查询操作的速度。
- **空间效率**：自增ID通常占用较少的空间，例如一个32位整数可以存储2^32个不同的值。
- **性能优势**：由于自增ID是连续的，因此在构建B+树索引时，新的记录总是添加到索引的末端，这减少了B+树的分裂和重组，提高了写入性能。

**UUID的特点**

- **全局唯一性**：UUID确保每个生成的值都是唯一的，这对于分布式系统特别有用。
- **无序性**：UUID通常是随机生成的，这意味着在B+树索引中，新的记录可能需要插入到中间位置，而不是总是添加到末尾。这会导致更多的磁盘I/O操作，降低性能。
- **存储开销**：UUID通常比自增ID占用更多空间，例如128位的UUID与32位的自增ID相比，前者占用的空间是后者的四倍。

**B+树中的存储顺序**

- **自增ID**：在B+树中，自增ID因为是连续递增的，所以自然地按照插入顺序排列，有利于快速查找和范围查询。
- **UUID**：UUID由于是随机生成的，在B+树中不会保持有序性，这意味着插入操作可能会导致节点分裂，影响性能。

**总结**

对于大多数情况，自增ID提供了更好的性能和空间效率，尤其是在对性能要求较高的应用中。然而，如果需要保证全局唯一性或者避免ID泄露业务信息的情况下，UUID是一个更好的选择。在选择使用哪种类型的ID时，需要根据具体的应用场景和需求来权衡。

> #### **问题6.** 查询数据时，到了B+树的叶子节点后，数据是如何查找的？

在数据库管理系统中，B+树是一种广泛使用的数据结构，用于组织索引数据以便快速检索。B+树的特点是所有的数据项都存储在叶子节点上，而内部节点仅包含指向叶子节点的指针以及用于索引的键值。B+树非常适合于磁盘存储，因为它可以有效地利用磁盘的读写块特性，减少磁盘I/O次数。

**普通索引 B+树的查找过程**

在普通索引的B+树中，叶子节点会存储索引键值和对应的行指针（rowid 或其他定位信息），这个行指针指向实际的数据行。当到达叶子节点后，查找过程如下：

1. **开始搜索**：从根节点开始向下遍历，直到找到合适的叶子节点。
2. **查找键值**：在叶子节点中查找匹配的键值。
3. **获取行指针**：一旦找到匹配的键值，就从叶子节点中提取对应的行指针。
4. **定位数据行**：使用行指针找到实际的数据行，进行进一步的操作。

**主键索引 B+树的查找过程**

在主键索引的B+树中，主键本身就是行的唯一标识符，因此主键索引的叶子节点中直接存储的是完整的数据行。这意味着当你按照主键索引进行查找时，可以直接在叶子节点中获取完整的数据行，而不需要额外的行指针来定位数据行。

1. **开始搜索**：同样从根节点开始向下遍历，直到找到合适的叶子节点。
2. **查找键值**：在叶子节点中查找匹配的键值。
3. **获取数据行**：一旦找到匹配的键值，就可以直接从叶子节点中获取完整的数据行。

**对比两种情况**

- **普通索引**：需要两次查找，第一次查找索引，第二次根据行指针查找数据。
- **主键索引**：只需要一次查找，直接在叶子节点中获取完整的数据行。

**性能差异**

- **普通索引**：由于需要两次查找，这可能导致更高的磁盘I/O开销，尤其是在数据量很大且磁盘访问较慢的情况下。
- **主键索引**：由于数据行直接存储在叶子节点上，因此性能更好，特别是在频繁读取的情况下。

总结来说，在普通索引中，B+树的叶子节点包含索引键值和行指针，而在主键索引中，B+树的叶子节点直接包含完整的数据行。这意味着主键索引在查找时更高效，因为它避免了额外的行定位步骤。不过需要注意的是，主键索引会占用更多的空间，因为它在每个叶子节点上存储了完整的数据行。

> #### **问题7.** InnoDB 与 MyISAM 的区别？如何选择存储引擎？

**一、 InnoDB 与 MyISAM 的区别**

**InnoDB 的特点**

- **事务支持**：InnoDB 支持 ACID（原子性、一致性、隔离性、持久性）事务特性。
- **行级锁定**：InnoDB 使用行级锁定，这意味着在并发操作中，它能够锁定特定的行而不是整个表。
- **外键支持**：InnoDB 支持外键约束，有助于确保引用完整性。
- **MVCC（多版本并发控制）**：InnoDB 使用 MVCC 来支持高并发读取，允许多个事务同时读取同一行的不同版本。
- **在线索引调整**：InnoDB 允许在表不被锁定的情况下添加或删除索引。
- **恢复机制**：InnoDB 支持崩溃恢复，能够在系统崩溃后恢复数据。
- **支持自动增长字段**：InnoDB 支持自动增长字段（AUTO_INCREMENT）。
- **支持大文件**：InnoDB 支持大于 4GB 的表空间文件。

**MyISAM 的特点**

- **表级锁定**：MyISAM 使用表级锁定，这在某些情况下可以减少锁定的粒度，但在并发操作中可能会限制性能。
- **全文索引**：MyISAM 支持全文索引，这对于搜索引擎和文档管理应用非常有用。
- **快速插入**：MyISAM 在插入大量数据时非常快，因为它不需要维护事务日志。
- **不支持事务**：MyISAM 不支持事务，这使得它在需要事务支持的场景下不太适用。
- **不支持外键**：MyISAM 不支持外键约束。

**二、如何选择引擎？**

**MyISAM** **：出现大量只读的情况用 MyISAM**，比如博客系统、新闻门户网站。**MyISAM** 适用于读密集型的应用、需要全文索引的应用或不需要事务支持的情况。

**InnoDB**  **：有频繁的读写操作时用 InnoDB** 比如 OA 办公系统。**InnoDB** 适用于需要事务支持、高并发读写操作和数据完整性的应用。

> #### **问题8.** InnoDB 引擎通过什么技术来保证事务的四个特性的呢？

事务看起来感觉简单，但是要实现事务必须要遵守 4 个特性，分别如下：

- **原子性（Atomicity）**：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样，就好比买一件商品，购买成功时，则给商家付了钱，商品到手；购买失败时，则商品在商家手中，消费者的钱也没花出去。
- **一致性（Consistency）**：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）。
- **隔离性（Isolation）**：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。
- **持久性（Durability）**：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？

- 持久性是通过 redo log （重做日志）来保证的；
- 原子性是通过 undo log（回滚日志） 来保证的；
- 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；
- 一致性则是通过持久性+原子性+隔离性来保证；

> #### **问题9.** 可重复读有没有幻读的问题？

答：还是存在幻读的问题，具体看下面那个链接

[MySQL 可重复读隔离级别，完全解决幻读了吗？ | 小林coding (xiaolincoding.com)](https://xiaolincoding.com/mysql/transaction/phantom.html#幻读被完全解决了吗)

> #### **问题10.** 讲一下MySQL的锁机制

MySQL 的锁机制主要包括行级锁、表级锁以及页级锁等不同层次的锁定方式。其中，InnoDB 存储引擎支持行级锁和间隙锁，而 MyISAM 存储引擎则支持表级锁。

##### 锁的类型

- **共享锁（S锁）**：允许事务读取数据，但不允许其他事务对数据进行修改。在 InnoDB 中，共享锁通常用于 SELECT 语句。
- **排他锁（X锁）**：允许事务读取和修改数据，阻止其他事务读取或修改相同的数据。排他锁通常用于 INSERT、UPDATE 和 DELETE 语句。

##### 锁的层次

- **行级锁**：锁定具体的行，允许其他事务访问表中的其他行。InnoDB 存储引擎使用行级锁，这有助于提高并发性能。
- **表级锁**：锁定整个表，阻止其他事务访问该表。MyISAM 存储引擎使用表级锁，这可能会限制并发性能。
- **页级锁**：锁定表的一部分，而不是整个表或单个行。InnoDB 支持页级锁，但在实践中很少使用。

##### 锁的策略

- **Next-Key Locking**：InnoDB 使用的一种锁定策略，它结合了 Record Locks 和 Gap Locks，旨在解决幻读问题。Next-Key Locks 锁定行本身以及行之间的间隙，以防止其他事务插入新的行。

##### 隔离级别与锁

不同的隔离级别会影响锁的行为：

- **读未提交**：最低的隔离级别，事务可以看到其他事务尚未提交的数据，不使用行级锁。
- **读提交**：事务只能看到已经提交的数据，使用行级锁。
- **可重复读**：InnoDB 的默认隔离级别，保证事务在执行期间看到的数据是一致的。使用 Next-Key Locking 来减少幻读的发生。
- **串行化**：最高的隔离级别，事务之间完全串行化执行，确保数据的一致性，但可能会影响性能。

##### 锁的获取与释放

- **锁的获取**：事务开始时，根据查询和操作的类型获取必要的锁。
- **锁的释放**：事务提交或回滚时，所有锁会被释放。此外，InnoDB 在事务开始时获取的锁会在事务结束时释放，这有助于减少锁等待的时间。

##### 死锁处理

- **死锁检测**：InnoDB 会定期检测死锁，一旦检测到死锁，它会选择一个事务进行回滚以解除死锁。
- **死锁预防**：通过合理的设计和事务管理策略来减少死锁发生的可能性，例如尽量缩短事务持续时间、按照固定的顺序获取锁等。

通过这些机制，MySQL 能够有效地管理并发访问，确保数据的一致性和事务的隔离性。

> #### **问题11.** 设计一个行级锁的死锁，举一个实际的例子

设计一个行级锁的死锁例子可以帮助理解 MySQL 中死锁是如何发生的以及如何解决这类问题。下面是一个简单的例子，展示如何构造一个死锁场景，并解释如何避免它。

##### 场景设定

假设有一个简单的表 `accounts`，包含两列 `account_id` 和 `balance`，用于存储账户信息。

```sql
INSERT INTO accounts (account_id, balance) VALUES (1, 100), (2, 200);
```

##### 死锁构造

我们将构造一个场景，其中两个事务分别尝试从账户 A 和账户 B 中转账给对方，但由于锁定顺序不同而导致死锁。

##### 事务 A

事务 A 尝试从账户 A 转账 50 到账户 B。

```sql
START TRANSACTION;

-- 获取账户 A 的锁
SELECT * FROM accounts WHERE account_id = 1 FOR UPDATE;

-- 更新账户 A 的余额
UPDATE accounts SET balance = balance - 50 WHERE account_id = 1;

-- 尝试获取账户 B 的锁
SELECT * FROM accounts WHERE account_id = 2 FOR UPDATE;

-- 更新账户 B 的余额
UPDATE accounts SET balance = balance + 50 WHERE account_id = 2;

COMMIT;
```

##### 事务 B

事务 B 尝试从账户 B 转账 50 到账户 A。

```sql
START TRANSACTION;

-- 获取账户 B 的锁
SELECT * FROM accounts WHERE account_id = 2 FOR UPDATE;

-- 更新账户 B 的余额
UPDATE accounts SET balance = balance - 50 WHERE account_id = 2;

-- 尝试获取账户 A 的锁
SELECT * FROM accounts WHERE account_id = 1 FOR UPDATE;

-- 更新账户 A 的余额
UPDATE accounts SET balance = balance + 50 WHERE account_id = 1;

COMMIT;
```

##### 死锁分析

在这个例子中，事务 A 首先锁定了账户 A，然后尝试锁定账户 B；而事务 B 则相反，先锁定了账户 B，再尝试锁定账户 A。这样，两个事务都在等待对方释放锁，从而形成了死锁。

##### 死锁检测与解决

- **死锁检测**：InnoDB 会周期性地检测死锁。一旦检测到死锁，它会回滚其中一个事务以解除死锁。
- **解决策略**：为了避免死锁，可以采用以下策略：
  - **按固定顺序获取锁**：始终按照相同的顺序获取锁，例如按 `account_id` 排序的顺序。
  - **减少事务持续时间**：尽量减少事务的执行时间，以减少锁的持有时间。
  - **使用悲观锁**：在事务开始时获取所有需要的锁，确保不会发生死锁。
  - **使用乐观锁**：在事务结束时才检查冲突，这种方法可能会导致重试，但可以减少死锁的机会。

##### 修改后的事务 A

修改事务 A 以按照固定的顺序获取锁。

```sql
START TRANSACTION;

  -- 按照固定的顺序获取锁
  -- 先锁定账户 A
  SELECT * FROM accounts WHERE account_id = 1 FOR UPDATE;
  UPDATE accounts SET balance = balance - 50 WHERE account_id = 1;
  -- 再锁定账户 B
  SELECT * FROM accounts WHERE account_id = 2 FOR UPDATE;
  UPDATE accounts SET balance = balance + 50 WHERE account_id = 2;
COMMIT;
```

##### 修改后的事务 B

修改事务 B 以按照相同的固定顺序获取锁。

```sql
START TRANSACTION;
  -- 按照固定的顺序获取锁
  -- 先锁定账户 A
  SELECT * FROM accounts WHERE account_id = 1 FOR UPDATE;
  UPDATE accounts SET balance = balance + 50 WHERE account_id = 1;
  -- 再锁定账户 B
  SELECT * FROM accounts WHERE account_id = 2 FOR UPDATE;
  UPDATE accounts SET balance = balance - 50 WHERE account_id = 2;
COMMIT;
```

##### 总结

通过上面的例子，我们可以看到如何构造一个简单的死锁场景，并学习如何通过修改事务逻辑来避免死锁的发生。通过遵循一定的锁定策略和事务设计原则，可以显著减少死锁的风险。

> #### **问题12.** 为什么mysql的底层使用b+树？

MySQL 底层使用 B+ 树的原因主要有以下几点：

1. **高效的范围查询**：B+ 树的叶子节点通过链表相连，形成有序链表结构。这个特点使得范围查询非常高效，只需要找到范围的起点，然后通过链表依次遍历即可。相比于 B 树，B+ 树在处理范围查询时更加高效，因为 B 树的范围查询需要逐层遍历树结构。
2. **磁盘 I/O 性能优化**：数据库中的索引通常会存储在磁盘上，而磁盘 I/O 的代价很高。B+ 树的节点通常设计得较大（包含多个键值对），这使得每次读取一个节点时能够获取更多的数据，从而减少磁盘 I/O 的次数。叶子节点中只存储数据的指针和键值，而非实际数据，这样每个节点可以容纳更多的键值对，提高了数据的存储密度和查询效率。
3. **稳定的查询性能**：B+ 树是一种平衡树，它确保了从根节点到任意叶子节点的路径长度相同。这样一来，所有数据的查询、插入和删除操作的时间复杂度都是 $O(log⁡n)$，这使得 B+ 树能够在大规模数据集上提供稳定的性能。
4. **更好的空间利用率**：B+ 树的非叶子节点只存储键值和指针，不存储数据，这样非叶子节点可以容纳更多的键值对，使树的高度相对较低，进一步减少了查询路径长度和磁盘 I/O 次数。
5. **易于维护和扩展**：由于 B+ 树的平衡性，插入和删除操作后树结构的调整比较简单，能够在保证性能的同时维护数据结构的稳定性。此外，B+ 树的叶子节点形成了有序的链表结构，非常适合顺序读写和批量操作。

综上所述，B+ 树在数据库中被广泛使用，尤其是在 MySQL 中作为默认的索引结构，主要是因为它在查询性能、磁盘 I/O 性能、空间利用率和易于维护等方面的综合优势。

> #### **问题13.** Redis为什么使用跳表而不是用B+树?

Redis 选择使用跳表（Skip List）而不是 B+ 树作为其底层数据结构，主要出于以下几个原因：

1. **实现简单性和维护成本低**

- 跳表的实现相对简单，它是一种基于链表的数据结构，通过增加多个层次的索引，使得查询、插入和删除操作可以在 $O(log⁡n)$ 的时间复杂度内完成。而 B+ 树则相对复杂，需要维护平衡树的结构，涉及节点的分裂和合并，这会增加实现的复杂性和维护成本。

2. **内存存储的适应性**

- Redis 是一个内存数据库，所有的数据都存储在内存中，而跳表在内存中表现良好。跳表主要依赖指针结构，这使得其在内存中操作非常高效，并且占用的内存较少。而 B+ 树更多地是为磁盘存储设计的，考虑了磁盘 I/O 的优化，节点较大，适合磁盘块读取，但在内存中的效率不如跳表。

3. **动态性和灵活性**

- 跳表在动态增删节点时，结构调整非常简单，不需要像 B+ 树那样进行复杂的节点分裂和合并。对于频繁插入和删除的操作，跳表能够更灵活地适应这些变化，维护操作较少。Redis 作为一个高性能数据库，需要处理大量的实时数据操作，跳表的灵活性非常适合这种场景。

4. **有序集合的实现**

- Redis 使用跳表来实现有序集合（Sorted Set），跳表天然支持顺序访问和范围查询，这与 Redis 的使用场景高度契合。而且，跳表支持按照顺序快速地插入和查找元素，这对于 Redis 的有序集合功能（如 ZSET）非常关键。

5. **随机性和概率保证**

- 跳表的性能虽然带有一定的随机性，但通过合理设置跳表的层高和概率因子，跳表的平均时间复杂度能够稳定在 $O(log⁡n)$，而且实现更为直观。B+ 树则依赖于严格的平衡维护，对于 Redis 这种追求极致性能的内存数据库，跳表在大多数情况下能够提供足够的效率。

6. **Redis 的设计哲学**

- Redis 的设计哲学偏向简单高效，使用尽可能简单的数据结构来实现功能强大的特性。跳表比 B+ 树更符合这一哲学，尤其是在内存场景下，跳表的优势更为明显。

综上所述，Redis 使用跳表而不是 B+ 树，主要是因为跳表在内存中操作更加高效、实现和维护相对简单、能够更灵活地处理动态数据变化，并且适应 Redis 的设计需求和场景。

> #### **问题14.**  过期删除策略和内存淘汰策略有什么区别？

区别：

- 内存淘汰策略是在内存满了的时候，redis 会触发内存淘汰策略，来淘汰一些不必要的内存资源，以腾出空间，来保存新的内容
- 过期键删除策略是将已过期的键值对进行删除，Redis 采用的删除策略是惰性删除+定期删除。

> #### **问题15.** Redis的缓存失效会不会立即删除？

不会，Redis 的过期删除策略是选择「**惰性删除+定期删除**」这两种策略配和使用。

- 惰性删除策略的做法是，**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。**
- 定期删除策略的做法是，**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key**。

> #### **问题16.** go 的并发工具有哪些？


在Go语言中，提供了多种工具和支持来帮助开发者编写并发程序。Go语言本身的设计就非常注重并发编程的支持，这主要体现在它的`sync`包和内置的`channel`机制上。下面是一些常用的并发工具和概念：

1. **goroutines** - goroutine是一个轻量级线程，由Go运行时调度。通过调用`runtime.Goroutine()`函数（通常通过`go`关键字启动一个函数或方法）可以创建一个新的goroutine。goroutines非常适合用于并发执行任务，尤其是I/O密集型的任务。
2. **channels** - channels是goroutines之间安全通信的一种方式。通过channels可以在不同的goroutines之间发送和接收数据。这是Go语言实现CSP（Communicating Sequential Processes）模型的核心。
3. **sync包** - 包括`sync.Mutex`，`sync.RWMutex`，`sync.WaitGroup`等类型，用于同步goroutines的执行。例如，`Mutex`用于保护共享数据免受并发修改，而`WaitGroup`则用于等待一组并发操作完成。
4. **context包** - `context`包提供了一个取消信号来传播有限期的生命周期到一个或者多个子goroutines。它可以帮助处理程序优雅地终止长时间运行的操作，比如HTTP请求处理中的数据库查询。
5. **sync/atomic包** - 提供了原子操作的功能，允许在无需显式加锁的情况下更新整数和指针类型的值，这对于高并发环境下的性能优化非常重要。
6. **select语句** - 类似于switch语句，但是专门用于从多个channel通信操作中选择一个准备好的操作执行。这可以用来实现非阻塞的channel操作，以及构建更复杂的并发模式。
7. **time.After/ticker** - `time`包中的`After`函数返回一个会在指定时间后关闭的channel，`Ticker`则会定期关闭一个channel。这些功能常用于定时任务或者设置超时。

> #### **问题17.** 有两个文件，每个文件有大约40亿url，内存4g，如何找到同时出现的url

要在有限的内存条件下（例如4GB）找出两个文件中同时出现的URL，可以采用一些高效的算法和技术来处理大规模数据集。这里提供一种基于哈希和布隆过滤器（Bloom Filter）的方法来解决这个问题。这种方法可以在较低的空间复杂度下近似解决问题。

**方法步骤**

1. **使用布隆过滤器预筛选**：
   - 由于直接将所有URL加载到内存中是不可行的，可以首先使用布隆过滤器（Bloom Filter）来存储第一个文件中的所有URL。布隆过滤器是一种空间效率极高的概率型数据结构，它可以用来测试一个元素是否属于一个集合。
   - 为第一个文件中的每个URL创建一个布隆过滤器，这样可以极大地减少内存消耗，尽管会有一定的误判率。
2. **遍历第二个文件**：
   - 对第二个文件中的每个URL，检查它是否可能存在于布隆过滤器中。如果布隆过滤器表明URL可能存在（即返回True），则进一步确认。
   - 由于布隆过滤器可能会产生误报（false positives），所以对于每一个可能存在的URL，需要再次从磁盘上的第一个文件中查找，以确认这个URL确实存在于第一个文件中。
3. **使用哈希表或数据库进行最终匹配**：
   - 对于那些通过布隆过滤器预筛选的URL，可以将它们哈希到内存中的哈希表中，或者写入到一个临时数据库中。这样可以高效地进行最终的匹配检查。
   - 对于每一个通过布隆过滤器检查的URL，检查它是否存在于哈希表或数据库中。如果存在，则记录下来。

> #### **问题18.** 设计一个微博的评论系统，要求展示热点评论，要求处理高并发访问场景。如何设计数据库表，如何保证高并发访问时微博不会挂掉。

设计一个微博的评论系统，特别是考虑到需要展示热点评论并且能够处理高并发访问场景，需要从数据库表的设计、架构的选择、缓存的使用等多个方面进行综合考虑。下面是一个基本的设计思路：

##### 1. 数据库表设计

**微博表（Weibo）**

- `id`：微博ID（主键，自增或UUID）
- `user_id`：发布微博的用户ID（外键）
- `content`：微博内容
- `created_at`：创建时间
- `updated_at`：更新时间

**评论表（Comments）**

- `id`：评论ID（主键，自增或UUID）
- `weibo_id`：评论所属的微博ID（外键）
- `user_id`：发表评论的用户ID（外键）
- `content`：评论内容
- `created_at`：创建时间
- `upvotes`：点赞数
- `is_hot`：是否为热点评论（布尔型，默认为false）

**点赞表（Upvotes）**

- `id`：点赞ID（主键，自增或UUID）
- `comment_id`：点赞的评论ID（外键）
- `user_id`：点赞的用户ID（外键）
- `created_at`：创建时间

##### 2. 高并发处理

**分布式数据库**

- **分片（Sharding）**：将数据分散到多个物理数据库上，每个数据库负责一部分数据。例如，可以根据微博ID或用户ID进行分片。
- **读写分离**：将读操作和写操作分开，使用主从复制技术，读操作可以从多个从库中读取，写操作则只在一个主库上进行。

**缓存机制**

- **Redis**：使用Redis作为缓存层，存储热点评论、用户信息等高频访问的数据，减少对数据库的直接访问。
- **Memcached**：也可以使用Memcached进行缓存，尤其适用于存储简单键值对数据。

**异步处理**

- **消息队列**：使用如RabbitMQ、Kafka等消息队列，将评论的处理异步化。例如，新评论发布后，不是立即更新评论数和点赞数，而是放入队列中异步处理。

通过上述设计方案，可以有效地应对微博评论系统的高并发访问需求，并且能够保证系统的稳定性和性能。当然，实际部署时还需要根据具体情况进行调整和优化。

> #### **问题19.** 生产者是如何发送数据到Kafka集群的，对应的策略是什么

在Kafka中，生产者（Producer）是负责向Kafka集群发送数据的应用程序。生产者可以发送数据到一个或多个主题（Topic），而主题则是Kafka中消息的分类或馈送名称。以下是生产者如何发送数据到Kafka集群的一般步骤，以及相关的策略：

##### 发送数据的基本流程

1. **创建生产者实例**：首先需要创建一个KafkaProducer实例。这通常涉及到配置一些属性，比如Broker列表（集群的位置）、序列化器（用于序列化键和值）、分区策略等。
2. **发送消息**：通过调用KafkaProducer实例的`send()`方法来发送消息。消息通常包含一个`ProducerRecord`对象，该对象指定了主题名称、可选的分区键、消息键和消息值。
3. **等待确认**：如果配置了同步发送模式，生产者将等待来自Broker的确认。如果是异步模式，生产者可以继续发送更多的消息，并通过回调函数来处理确认结果。
4. **关闭生产者**：当不再需要发送消息时，调用`close()`方法来关闭生产者实例，确保所有未完成的消息都被发送并且所有资源都被释放。

##### 发送策略

1. **同步 vs 异步**：
   - **同步发送**：每条消息发送后必须等待Broker的确认才能继续发送下一条消息。这种方式保证了消息发送的可靠性，但吞吐量相对较低。
   - **异步发送**：生产者可以连续发送多条消息，不必等待每条消息的确认。这种方式提高了吞吐量，但需要正确处理失败的消息，可能需要重试机制。
2. **分区策略**：
   - 生产者可以指定一个分区策略来决定消息发送到哪个分区。默认情况下，Kafka使用轮询（round-robin）的方式将消息均匀分布到各个分区。但是，也可以自定义分区器来实现更复杂的逻辑，例如基于消息键来确定分区。
3. **重试策略**：
   - 当消息发送失败时，可以配置重试机制。重试次数、重试间隔等都是可以配置的参数。
4. **批量发送**：
   - 生产者可以配置批量发送的大小和延迟时间，以提高网络利用率。这意味着生产者不会立即发送每条消息，而是等待达到一定的消息数或时间阈值后再批量发送。
5. **压缩**：
   - 为了节省带宽，生产者可以选择压缩消息。Kafka支持多种压缩算法，如GZIP、Snappy和LZ4等。
6. **ACKs（确认）级别**：
   - `0`：生产者不会等待任何来自Broker的确认。这种方式提供最高的吞吐量，但没有任何消息丢失保障。
   - `1`：只要Leader Broker确认收到消息即可。这种方式提供了较好的吞吐量和基本的消息丢失保护。
   - `-1` 或 `all`：所有参与的Broker（包括Follower）都需要确认消息的接收。这是最可靠的方式，但也可能影响性能。

通过合理的配置这些策略，生产者可以根据应用程序的具体需求来优化Kafka的数据发送过程。

> #### **问题20. 如何设计一个秒杀系统？**

[如何设计一个秒杀系统？（完结）](https://www.yuque.com/itwanger/gykdzg/mayf4g#af24e417) 密码：gqya

秒杀系统有 9 个细节：

1. 瞬时高并发
2. 页面静态化
3. 秒杀按钮
4. 读多写少
5. 缓存问题
6. 库存问题
7. 分布式锁
8. MQ异步处理
9. 如何限流

##### 读多写少

秒杀过程中，一般要先查询库存是否足够，如果足够才允许下单，写入数据库。如果不够，则直接返回已经抢完。

这就是典型的`读多写少`场景。

解决办法：使用缓存

##### 缓存问题

###### 缓存击穿问题

解决办法：缓存预热，分布式锁

##### MQ异步处理

秒杀系统一般是三个核心流程：秒杀，下单，支付

而这三个核心流程中，真正并发量大的是秒杀功能，下单和支付功能实际并发量很小。所以，我们在设计秒杀系统时，有必要把下单和支付功能从秒杀的主流程中拆分出来，特别是下单功能要做成mq异步处理的。而支付功能，比如支付宝支付，是业务场景本身保证的异步。

